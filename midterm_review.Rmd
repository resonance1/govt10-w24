---
title: "Midterm Review"
author: ""
header-includes:
   - \usepackage{pdfpages}
output:
  pdf_document: default
---

```{r setup, echo=F}
library(knitr)
opts_chunk$set(tidy.opts = list(width.cutoff = 60), tidy = TRUE)
knitr::opts_chunk$set(error = TRUE)
```


## Conceptual Practice Questions

1. Your friend Mildred tells you that she has a designed a study to test the effects of watching NBC News on political preferences and obtained compelling results. Mildred's study surveys the political preferences of 100 student volunteers. From this larger sample, she selected 20 strong Democrats and 20 strong Republicans, and tasks them with watching NBC News every night. At the end of the study, she measured political preferences again. According to Mildred, watching NBC news makes the general population more Democratic: over time, both groups displayed more agreement with the Democratic party.

Identify two errors in Mildred's research design. If you wanted to rerun the study, how might you redesign it to obtain a more robust estimate of the effect of watching NBC news on political opinions?

2. Your friend Prunella designed an experiment to test whether exposure to videos showing squirrels raiding bird feeders reduces positive attitudes towards squirrels. 

Prunella randomly selected 20 Americans, and then randomly assigned 10 to watch the squirrel video. Conducting a balance check, Prunella found that the treated and control group had approximately the same prior interest in squirrels. She concludes that the effect she identifies is causal. 

Do you agree with her reasoning? 

3. If X is negatively correlated with Y, then Y is ____ correlated with X.  

4. The difference-in-differences design is invalid if there are pre-existing differences between groups (TRUE/FALSE) 

5. If the variable _Income_ has the following values: "Less than 20k", "Between 30k and 50k", "50k to 100k", and "100k+", can we treat it as an ordinal variable by recoding "Less than 20k" to 1, "Between 30k and 50k" to 2, etc?




## Difference in Differences: Long vs Wide

In many (but not all) states in Austria, voting in parliamentary elections was compulsory, punishable by fines. In 1992, the Federal Constitutional Court announced that this practice was unconstitutional and struck down the law. 

We are interested in finding out whether the repeal of the law (and the accompanying reduction in turnout) reduced support for left-wing parties. States that were forced to abolish compulsory voting are considered the treatment group, while states that never enacted compulsory voting are in the control group. 

```{r}
library(tidyverse)
austria_long <- read.csv('./class_data/austria_long.csv')

#download.file("https://raw.githubusercontent.com/resonance1/govt10-w24/main/class_data/austria_long.csv","austria_long.csv")
#austria_long <- read.csv("austria_long.csv")
```

The dataset contains a partial sample of election results from Austrian municipalities, and includes following variables:

name                    name of the municipality
state                   name of the state
treated                 1 if the state practiced compulsory voting prior to 1992, 0 otherwise
socialist_voteshare     the percentage of votes cast for the socialist party in an election year

Step 1: determine the treatment year, and identify the time periods immediately before (pre) and immediately after (post)
Step 2: determine the treatment and outcome variables

### Longitudinal data (many rows per observation; 1 outcome column, 1 time column)

Step 3: get the average values of the outcome, for the treated and control units, _separately for the pre and post period_
To do this, filter for both year and treatment status

```{r}

treat_pre <- 
treat_post <- 

control_pre  <- 
control_post  <-

```

Step 4: Calculate the longitudinal differences for the treated and control (post-pre)
Step 5: Subtract the longitudinal difference of the control from the treated group.

```{r}

```

Step 6: Evaluate the parallel trends assumption by plugging in different time values prior to the treatment

```{r}


```

### Wide data (1 row per observation; many outcome x time columns)

```{r}

austria_wide <- read.csv('./class_data/austria_wide.csv')

#download.file("https://raw.githubusercontent.com/resonance1/govt10-w24/main/class_data/austria_wide.csv","austria_wide.csv")
#austria_wide <- read.csv("austria_wide.csv")

```

Step 3: Create a longitudinal difference variable using mutate()

```{r}


```

Step 4: Use group_by %>% summarize() to get the average longitudinal difference for the treated/control
Step 5: Subtract control from treated

```{r}

```

Step 6: Check parallel trends by substituting in prior years

```{r}

```

### Plotting DiD

Step 1: Start with longitudinal data
Step 2: Filter by the treated variable, group by year, and then get the average. Remember to label your variable in summarize()

```{r}

treated <-
control <-

```

Step 3: Put one of the results in plot(), and the other in lines()

```{r}

```


## Regression Discontinuity


We are going to examine the monetary returns to political office in the United Kingdom, by comparing the lifetime wealth of candidates who barely won a parliamentary election to those candidates who barely lost.

This study looks at the winners and losers of a single election. The sample is limited to those individuals who had died before the study was completed (2009); this way their full earnings over the lifecourse can be observed.

The assumption is that candidates who barely won an election are similar to those who barely lost. However, the relatively small sample size of candidates implies that we cannot restrict the sample to very small values of the running variable (in this case, victory or loss margin). We will explore whether we can obtain findings by examining observations on either side of the victory/loss cutoff, selecting a cutoff that enables the Law of Large Numbers to apply.

Relevant variables:

ln.gross        Log of wealth upon death (from probate records)
yob             Year of birth
yod             Year of death
female          Whether candidate is female(1) or not (0)
margin.pre      Average victory or loss margin in prior elections (a signal of candidate quality)
margin          Victory or loss margin in the election being assessed; 
                    this determines the discontinuity, and is the "running variable" we will use to narrow the analysis window
party           political party

```{r}
library(tidyverse)

british_mp <- read.csv("./class_data/MPs.csv")


#download.file("https://raw.githubusercontent.com/resonance1/govt10-w24/main/class_data/MPs.csv","MPs.csv")
#british_mp <- read.csv("MPs.csv")



```


Step 1: Identify the running variable
Step 2: Create a treatment indicator based on the running varialbe

```{r}

```

Step 3: Narrow the analysis window using the running variable

```{r}

```

Step 4: Treat as a natural experiment: evaluate randomization

```{r}

```

Step 5: Obtain ATE

```{r}

```


## Treatment Effects with Multiple Groups


### Scenario 1: You have a dataset with a single treatment variable, but multiple treatments

```{r}
savings <- read.csv("./class_data/rosca.csv")


#download.file("https://raw.githubusercontent.com/resonance1/govt10-w24/main/class_data/rosca.csv","rosca.csv")
#savings <- read.csv("rosca.csv")


```

Solution: Use group_by %>% summarize() to get values for all groups

```{r}

```

Remember to subtract the control group from _each_ treated group


### Scenario 2: You have a dataset with multiple binary treatment variables

```{r}
savings2 <- read.csv("./class_data/rosca2.csv")

#download.file("https://raw.githubusercontent.com/resonance1/govt10-w24/main/class_data/rosca2.csv","rosca2.csv")
#savings2 <- read.csv("rosca2.csv")

```

Solution: Use filter() to get the correct groups

```{r}

```

Alternative: Create a new variable with the correct values for each treatment

```{r}

```

## Balance

For RCTs and Natural Experiments, we need to verify that EVERY characteristic _measured before the treatment_, is on average, similar across the treated and control groups. Without this 'balance', we cannot interpret the results as causal. 

Let's look at the GOTV study:


```{r}
gotv <- read.csv("./class_data/social.csv")
#download.file("https://raw.githubusercontent.com/resonance1/govt10-w24/main/class_data/social.csv","social.csv")
#gotv <- read.csv("social.csv")

```



## Distributions

We assess distributions for the following reasons:

- It tells us whether skew in the outcome variable might lead to misleading conclusions
- It tells us whether the treatment effect was driven by outliers or not

Let's look at the distribution of the main outcome variable in the savings experiment using a histogram

```{r}

```

Let's look across the treated and control groups. Whenever we are comparing distributions, it's fastest to use a boxplot

```{r}


```

Now let's examine the median difference

```{r}

```

## Standard deviation

Standard deviation is a measure of dispersion. Let's look at the standard deviation of age in this experiment

```{r}

```

Now let's look at the standard deviation of the outcome

```{r}

```


## Expected error

A polling company sampled 500 Americans to ask them if they approved supplying arms to Ukraine. On a scale of 1 to 5, where 1 meant "strongly oppose" and 5 meant "strongly support", the average response was 4.12. The standard deviation was 0.25. What was the expected error of this poll?

```{r}

```

A reminder on why this works:

```{r}
state <- c(rep(1,40000),rep(0,60000))
sd(state)/sqrt(10000)
```

If we had a sample of size 10k, how close would we be on average to the true answer?

```{r}

n<-10000
samples <- 1000
out <- c()
for (i in 1:samples){
  out <- c(out,mean(sample(state,n,replace=FALSE)))
}
hist(out,breaks=200)


```




