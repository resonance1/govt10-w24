---
title: "Class 20"
author: " "
header-includes:
   - \usepackage{pdfpages}
output:
  pdf_document: default
---

```{r setup, echo=F}
library(knitr)
opts_chunk$set(tidy.opts = list(width.cutoff = 60), tidy = TRUE)
knitr::opts_chunk$set(error = TRUE)
```

# Plan
- Confidence Intervals Review
- Group work: Confidence Intervals
- Intro to t-statistics (lecture)
- t-statistics in R

# Review: qnorm()

```{r}
# Normal distribution (don't need to know this code)
x <- seq(-4, 4, length=100)
hx <- dnorm(x)
plot(x,hx,lty=1,type="l")

# 90% confidence interval

#abline(v=qnorm(),col="burlywood")
#abline(v=qnorm(),col="burlywood")

# 95% confidence interval

#abline(v=qnorm(),col="thistle")
#abline(v=qnorm(),col="thistle")

# 99% confidence interval

#abline(v=qnorm(),col="darkgoldenrod")
#abline(v=qnorm(),col="darkgoldenrod")

```


# Group Work: Confidence Intervals

Let's re-evaluate the study on racial bias in hiring. 

```{r}
resume <- read.csv("./class_data/resume.csv")

#download.file("https://raw.githubusercontent.com/resonance1/govt10-w24/main/class_data/resume.csv","resume.csv")
#resume <- read.csv("resume.csv")
```

In this experiment, identical resumes were sent out, except for the signaled race and gender, which was randomly assigned. We are interested in whether a resume received a call back from an employer or not.

Variables:
race    Signaled race on resume
sex     Signaled gender on resume
call    A binary variable indicating a call back (1) or not (0) 

1.1 First, calculate the average treatment effect:

Avg (Callback for White Resumes) - Avg (Callback for Black Resumes) 

```{r}

```

1.2 Now calculate the standard error for this difference in means. You can either use this formula:
sqrt( (sd_treatment^2 / n_treatment) + (sd_control^2 / n_control)), or a regression.

```{r}
n_treatment <- 
n_control <-
sd_treatment <- 
sd_control <-
```

1.3 Calculate a 90% confidence interval for the difference in means. 

```{r}

```

1.4 Can we conclude based on 1.3 that there is likely racial bias in hiring, with 90% confidence?


1.5: Would this change with a 99% confidence interval (critical value = 2.58)?

```{r}

```

1.6 Conceptual question:

The 90% confidence interval for the average of Group A is -0.04 to 0.07
The 90% confidence interval for the average of Group B is -0.03 to 0.17

Can we conclude that B > A?



# Lecture: t-distributions and t-statistics

## Demonstration in R

Compare t to normal (don't need to know this code)
```{r}
# Do not need to know this code
n <- samplesize <- 5
x <- seq(-4, 4, length=100)
hx <- dnorm(x)
plot(x,hx,lty=1,type="l",col="blue")
lines(x, dt(x,n-1), lwd=2, col="red")
```
For smaller sample sizes, we can use _qt()_ to obtain critical values and confidence intervals. This is the equivalent of _qnorm_ for the t-distribution. qt() requires us to state the degrees of freedom.

Let's obtain critical values for a 95% confidence interval, with a sample size of 10

```{r}
# qt( level, df)
```

We can use qt() all the time to be conservative, but if the sample size is large it will be similar to qnorm(). Let's use qt() for the resume example, constructing a 90% confidence interval

```{r}

```


# t-statistics

Manual calculation of a t-statistic:

Mean:          .19
Sample SD:   .3294
Sample Size:    20

```{r}

# First calculate the standard error

# Then calculate the t-statistic

```

Manual calculation of a t-statistic for a difference in means:

```{r}
chechen <- read.csv("./class_data/chechen.csv")

#download.file("https://raw.githubusercontent.com/resonance1/govt10-w24/main/class_data/chechen.csv","chechen.csv")
#chechen <- read.csv("chechen.csv")

result <- chechen %>% group_by(fire) %>%
summarize(out = mean(postattack), n = n(), variance = var(postattack))

diff <- result$out[2] - result$out[1]
se <- sqrt(result$variance[2]/result$n[2] + result$variance[1]/result$n[1])

# Calculate t-statistic (ate/se)

# Alternative: regression

```

What does a t-statistic of -1.33 mean?

```{r}
# Do not need to know this code
n  <- 318
x <- seq(-4, 4, length=100)
plot(x,dt(x,n-1),lty=1,type="l")
abline(v=-1.33)
```


The _t.test_ command can also rapidly generate t-statistics. It is more generalizable that regression, since we can do it for a single variable (rather than a relationship between two variables)

## One sample t-test (for a single distribution):

```{r}
#t.test(, mu = 0)
```

## Two sample t-test  (t-test for difference in means):

Chechen ATE t.test:

```{r}
#t.test(, , mu = 0, var.equal=F)
```




_Only If Time_


## Examples

Returning to the resume experiment, let's obtain a t-statistic to formalize the hypothesis that the true racial discrimination in our sample is 0

```{r}

```

We can also use t-tests to check for accurate randomization. Let's check that sex was correctly randomized:

```{r}

```


# Group Work

Recall the Kenyan savings experiment:

fol2_amtinvest            The outcome (investment in Kenyan shillings)
encouragement             1 if the person is in the control group, 0 otherwise
locked_box                1 if the person is in the locked box group, 0 otherwise
safe_box                  1 if the person is in the safe_box group, 0 otherwise
bg_b1_age                 Age of participant
bg_married                Whether participant is married (1) or not (0)
bg_female                 Whether participant is female (1) or not (0)

```{r}
kenya <- read.csv("./class_data/rosca2.csv")

#download.file("https://raw.githubusercontent.com/resonance1/govt10-w24/main/class_data/rosca2.csv","kenya.csv")
#kenya<- read.csv("kenya.csv")

kenya <- subset(kenya,has_followup2 == 1)
```

Use t-tests to check whether age, marital status, and female are randomized correctly. Focus just on individuals assigned to the locked_box and encouragement (control) groups for now.

```{r}

```



## Check-in

1. On a scale ranging between 1 (Too Hard) and 10 (Too Easy), how was today's class: 
2. What was the easiest thing to understand?
3. What was the most difficult thing to understand?


